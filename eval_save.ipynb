{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "from datasets import Audio\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer, pipeline\n",
    "from accelerate import PartialState, prepare_pippy\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "from torch.distributed.pipelining import Pipe\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-small\"\n",
    "cache_dir = '/mnt/8THDD0/storage/huggingface'\n",
    "set_seed(42)\n",
    "target_lang = 'zh'\n",
    "# model_name = \"openai/whisper-large-v3-turbo\"\n",
    "output_dir = \"/mnt/8THDD0/storage/train/output/\"+ model_name.split('/')[1] +\"-\" + target_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"zh\", task=\"transcribe\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"automatic-speech-recognition\", model=output_dir+'/checkpoint-30000', tokenizer=tokenizer)\n",
    "try:\n",
    "    pipe.save_pretrained(output_dir + '/final')\n",
    "except:\n",
    "    pipe.save_pretrained(output_dir + '/result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import torch\n",
    "from evaluate import load\n",
    "\n",
    "# torch.setnum_threads(1)\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"yue\", split=\"test\")\n",
    "\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"/mnt/8THDD0/storage/train/output/whisper-small-zh/final/\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"/mnt/8THDD0/storage/train/output/whisper-small-zh/final/\").to(\"cuda\")\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(batch['sentence'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda\"))[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch\n",
    "\n",
    "result = common_voice.map(map_to_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer = load(\"cer\")\n",
    "print(100 * cer.compute(references=result['test']['reference'], predictions=result['test'][\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "\n",
    "# Define the path to your local model directory\n",
    "model_path = '/mnt/8THDD0/storage/train/output/whisper-small-zh/final/'\n",
    "\n",
    "# Define the name of your repository on Hugging Face (must include username)\n",
    "repo_name = 'JackyHoCL/whisper-small-cantonese-yue-english'\n",
    "\n",
    "# Push the model to the repository\n",
    "pipeline(\"automatic-speech-recognition\", model=model_path).push_to_hub(repo_name)\n",
    "\n",
    "print(f\"Model successfully uploaded to {repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ct2-transformers-converter --model JackyHoCL/whisper-small-cantonese-yue-english --output_dir whisper-small-cantonese-yue-english-ct2 --copy_files tokenizer.json preprocessor_config.json --quantization float16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
